<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> LLM Learning Roadmap | Lance Yu </title> <meta name="author" content="Lance Yu"> <meta name="description" content="important llm models since 2017"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9C%8D%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://whoislance.github.io/blog/2025/llm-roadmap/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav mx-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">Resume </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link"><i class="ti ti-search"></i></span> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">LLM Learning Roadmap</h1> <p class="post-meta"> Created on April 13, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/cs"> <i class="fa-solid fa-hashtag fa-sm"></i> CS</a>   <a href="/blog/tag/ml"> <i class="fa-solid fa-hashtag fa-sm"></i> ML</a>   <a href="/blog/tag/nlp"> <i class="fa-solid fa-hashtag fa-sm"></i> NLP</a>   <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> LLM</a>   ·   <a href="/blog/category/code"> <i class="fa-solid fa-tag fa-sm"></i> Code</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025Q2/1-480.webp 480w,/assets/img/2025Q2/1-800.webp 800w,/assets/img/2025Q2/1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/2025Q2/1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p><a href="https://tomohiroliu22.medium.com/66%E5%80%8B%E5%A4%A7%E5%9E%8B%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8Bllm%E7%B6%93%E5%85%B8%E8%AB%96%E6%96%87-0fcdab74e822" rel="external nofollow noopener" target="_blank">66個大型語言模型LLM經典論文</a></p> <h1 id="encoder">Encoder</h1> <h2 id="transformer">Transformer</h2> <p><strong>《Attention Is All You Need》</strong>（2017）</p> <p>https://arxiv.org/pdf/1706.03762.pdf</p> <ul> <li> <strong>贡献</strong>：提出Transformer架构，取代传统RNN/CNN，奠定了所有现代LLM的基础。核心创新是自注意力机制，支持并行计算和长距离依赖建模610。</li> <li> <strong>研读重点</strong>：多头注意力机制、位置编码、编码器-解码器结构。</li> </ul> <p><strong>《Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context》</strong>（2019）</p> <p>https://arxiv.org/pdf/1901.02860</p> <ul> <li> <strong>Abstract</strong>：讓Transformer可以吃更長的句子</li> </ul> <p><strong>《Reformer: The Efficient</strong> <strong>Transformer</strong><strong>》</strong>（2020）</p> <p>https://arxiv.org/pdf/2001.04451.pdf</p> <ul> <li> <strong>Abstract</strong>：讓Transformer運算更快、使用記憶體更有效</li> </ul> <h2 id="bert族">BERT族</h2> <p><strong>《</strong><strong>BERT</strong><strong>: Pre-training of Deep Bidirectional</strong> <strong>Transformers</strong><strong>》</strong>（2018）</p> <p>https://arxiv.org/pdf/1810.04805</p> <ul> <li> <strong>贡献</strong>：引入双向Transformer编码器，通过掩码语言模型（MLM）和下一句预测（NSP）任务，显著提升文本理解能力610。</li> <li> <strong>研读重点</strong>：双向上下文建模与预训练任务设计。</li> </ul> <p><strong>《</strong><strong>ALBERT</strong><strong>:</strong> <strong>A Lite BERT</strong> <strong>for Self-supervised Learning of Language Representations》</strong>（2019）</p> <p>https://arxiv.org/pdf/1909.11942.pdf</p> <ul> <li> <strong>Abstract</strong>：我把BERT參數減少，然後加上了一個酷酷的自监督学习</li> </ul> <p><strong>《RoBERTa: A Robustly Optimized</strong> <strong>BERT</strong> <strong>Pretraining Approach》</strong>（2019）</p> <p>https://arxiv.org/pdf/1907.11692.pdf</p> <ul> <li> <strong>Abstract</strong>：我用了更多資源、更猛的方法訓練一個更猛的BERT</li> </ul> <p><strong>《DistilBERT, a distilled version of</strong> <strong>BERT</strong><strong>: smaller, faster, cheaper and lighter》</strong>（2019）</p> <ul> <li> <strong>Abstract</strong>：利用知識蒸餾訓練更小的BERT。</li> </ul> <h2 id="ernie">ERNIE</h2> <p><strong>《ERNIE: Enhanced Language Representation with Informative Entities》</strong>（2019）</p> <p>https://arxiv.org/pdf/1905.07129</p> <ul> <li> <strong>贡献</strong>：将知识图谱融入BERT，提升模型对结构化知识的理解能力，开辟知识增强型LLM方向610。</li> <li> <strong>研读重点</strong>：知识注入方法、异构信息融合。</li> </ul> <h1 id="decoder">Decoder</h1> <h2 id="gpt-1">GPT-1</h2> <p><strong>《Improving Language Understanding by Generative Pre-Training》（GPT-1）</strong>（2018）</p> <p>https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf</p> <ul> <li> <strong>贡献</strong>：首次将Transformer解码器用于生成式预训练，提出“预训练+微调”范式，验证了无监督预训练在NLP任务中的有效性610。</li> <li> <strong>研读重点</strong>：自回归语言模型、任务适配微调方法。</li> </ul> <h2 id="gpt-2"><strong>GPT-2</strong></h2> <p><strong>《Language Models are Unsupervised Multitask Learners》（GPT-2）</strong>（2019）</p> <ul> <li> <strong>贡献</strong>：证明大规模模型可通过无监督预训练实现多任务Zero-Shot学习，推动模型参数向百亿级扩展610。</li> <li> <strong>研读重点</strong>：Zero-Shot推理能力与模型规模的关系。</li> </ul> <h2 id="gpt-3">GPT-3</h2> <p><strong>《Language Models are Few-Shot Learners》（</strong><strong>GPT-3</strong><strong>）</strong>（2020）</p> <p>https://arxiv.org/pdf/2005.14165</p> <ul> <li> <strong>贡献</strong>：千亿参数模型展示出强大的上下文学习（In-Context Learning）能力，推动了对“涌现能力”的研究210。</li> <li> <strong>研读重点</strong>：Few-Shot提示工程、模型规模与泛化性能的关系。</li> </ul> <p><strong>《Scaling Laws for Neural Language Models》</strong>（2020）</p> <ul> <li> <strong>Abstract</strong>：最早的LLM規模定律全面分析</li> </ul> <p>https://arxiv.org/pdf/2001.08361.pdf</p> <h2 id="gpt-4">GPT-4</h2> <p>GPT-4 Technical Report (2023)</p> <p>https://arxiv.org/pdf/2303.08774.pdf</p> <ul> <li> <strong>Abstract</strong>：目前世界上最強的LLM之一</li> </ul> <h2 id="instructgpt">InstructGPT</h2> <p><strong>Training language models to follow instructions with human feedback</strong> （2022）</p> <p>https://arxiv.org/pdf/2203.02155.pdf</p> <ul> <li> <strong>Abstract</strong>：ChatGPT的前身，讓人類來教GPT-3社會化</li> </ul> <h2 id="llama">LLaMA</h2> <p>LLaMA: Open and Efficient Foundation Language Models （2023）</p> <ul> <li> <strong>Abstract</strong>：最有名的開源LLM第一代</li> </ul> <p>https://arxiv.org/pdf/2302.13971.pdf</p> <p>Llama 2: Open Foundation and Fine-Tuned Chat Models （2023）</p> <p>https://arxiv.org/pdf/2307.09288.pdf</p> <ul> <li> <strong>Abstract</strong>：開源LLM第二代，可以和人對話了</li> </ul> <h1 id="decoder-encoder">Decoder-Encoder</h1> <h2 id="unilm">UniLM</h2> <p><strong>《Unified Language Model Pre-training for Natural Language Understanding and Generation》</strong>（2019）</p> <p>https://arxiv.org/pdf/1905.03197.pdf</p> <ul> <li> <strong>Abstract</strong>：讓我們把NLU和NLG預訓練統一吧</li> </ul> <h2 id="t-5">T-5</h2> <p><strong>《Exploring the Limits of</strong> <strong>Transfer Learning</strong> <strong>with a Unified Text-to-Text</strong> <strong>Transformer</strong><strong>》（T5）</strong>（2020）</p> <p>https://arxiv.org/pdf/1910.10683</p> <ul> <li> <strong>贡献</strong>：将各类NLP任务统一为文本到文本的框架，验证了模型泛化能力的极限611。</li> <li> <strong>研读重点</strong>：任务统一化设计、模型容量与数据量的平衡。</li> </ul> <h2 id="bart">BART</h2> <p><strong>《</strong><strong>BART</strong><strong>: Denoising Sequence-to-Sequence Pre-training》</strong>（2019）</p> <p>https://arxiv.org/pdf/1910.13461</p> <ul> <li> <strong>贡献</strong>：结合双向编码器与自回归解码器，支持文本生成与重构任务，成为多任务适配的经典架构1012。</li> <li> <strong>研读重点</strong>：去噪自编码预训练、多任务适应性。</li> </ul> <p><strong>《Multimodal Chain-of-Thought》</strong>（2023，参考多模态LLM综述）</p> <ul> <li> <strong>贡献</strong>：扩展思维链（CoT）至多模态推理，推动LLM在视觉-语言任务中的复杂推理能力。</li> <li> <strong>研读重点</strong>：多模态信息整合、跨模态推理框架。</li> </ul> <p><strong>《LoRA: Low-Rank Adaptation of Large Language Models》</strong>（2021）</p> <ul> <li> <strong>贡献</strong>：提出低秩适配微调方法，显著降低大模型微调成本，成为轻量化部署的核心技术。</li> <li> <strong>研读重点</strong>：参数高效微调、适配器设计原理。</li> </ul> </div> </article> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Lance Yu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?3f95cd4b032198a059ab2c79c1671def"></script> </body> </html>